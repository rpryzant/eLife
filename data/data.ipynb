{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import nltk\n",
    "import random\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "import os\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (20,21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# make dataframe holding disagreements\n",
    "\n",
    "DATA_ROOT = \"/Users/rpryzant/metascience/eLife/data/\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(DATA_ROOT + \"kyle/tolabel.csv\", sep=\"|\")\n",
    "df = df[[\"Manuscript no.\", \"Reviewer ID\", \"CleanedComments\", \"Rec\", \"Suitable\", \"ShouldBe\", \"HumanLabel\"]]\n",
    "df = df.set_index([\"Manuscript no.\"])\n",
    "scored_bert = pd.read_csv(DATA_ROOT + \"kyle/eval_results_full_allelife.txt\", \n",
    "                          sep=\"\\t\", names=[\"id\", \"score\", \"dummy\", \"text\"])\n",
    "\n",
    "\n",
    "list(scored_bert.sort_values(by=\"score\", ascending=False).iloc[1:10,][\"text\"])\n",
    "df[\"score\"] = list(scored_bert.score)\n",
    "df[\"Text\"] = list(scored_bert.text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "e = pd.read_csv(DATA_ROOT + \"raw/eLife_Paper_history_2019_03_15.csv\")\n",
    "e[\"Manuscript no.\"] = e[\"ms\"]\n",
    "e = e.set_index([\"Manuscript no.\"])\n",
    "e = e.dropna(subset=[\"full_decision\"])\n",
    "\n",
    "# to get finaldecision, take last non-NA decision of the ones listed here\n",
    "# note that this excludes rejected by initial decision\n",
    "e[\"FinalDecision\"] = e.apply(lambda x: list(x[[\"full_decision\", \"rev1_decision\", \"rev2_decision\", \"rev3_decision\", \"rev4_decision\"]].dropna())[-1], axis=1)\n",
    "e[\"outcome\"] = np.where(e[\"FinalDecision\"] == \"Accept Full Submission\", 1, 0)\n",
    "\n",
    "df_e = df.join(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2684\n",
      "7021\n"
     ]
    }
   ],
   "source": [
    "# get disagreements\n",
    "\n",
    "df_e[\"review_outcome\"] = \"none\"\n",
    "df_e[\"zscore\"] = (df_e.score - np.mean(df_e.score))/np.std(df_e.score)\n",
    "df_e.loc[(df_e.zscore > 1) & (df_e.outcome == 1), \"review_outcome\" ] = \"pos_pos\"\n",
    "df_e.loc[(df_e.zscore > 1) & (df_e.outcome == 0), \"review_outcome\" ] = \"pos_neg\"\n",
    "df_e.loc[(df_e.zscore < -1) & (df_e.outcome == 0), \"review_outcome\" ] = \"neg_neg\"\n",
    "df_e.loc[(df_e.zscore < -1) & (df_e.outcome == 1), \"review_outcome\" ] = \"neg_pos\"\n",
    "\n",
    "# papers with disagreement\n",
    "disagreement = df_e.loc[(df_e.review_outcome == \"pos_neg\") | (df_e.review_outcome == \"neg_pos\")]\n",
    "disagreement_papers = df_e.loc[set(disagreement.index)]\n",
    "\n",
    "print(len(disagreement))\n",
    "print(len(disagreement_papers))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer ID</th>\n",
       "      <th>CleanedComments</th>\n",
       "      <th>Rec</th>\n",
       "      <th>Suitable</th>\n",
       "      <th>ShouldBe</th>\n",
       "      <th>HumanLabel</th>\n",
       "      <th>score</th>\n",
       "      <th>Text</th>\n",
       "      <th>ms</th>\n",
       "      <th>type</th>\n",
       "      <th>...</th>\n",
       "      <th>rev3_decision_dt</th>\n",
       "      <th>rev4_qc_dt</th>\n",
       "      <th>rev4_decision</th>\n",
       "      <th>rev4_decision_dt</th>\n",
       "      <th>p.poa_dt</th>\n",
       "      <th>p.vor_dt</th>\n",
       "      <th>FinalDecision</th>\n",
       "      <th>outcome</th>\n",
       "      <th>review_outcome</th>\n",
       "      <th>zscore</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manuscript no.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>34827</td>\n",
       "      <td>3163.0</td>\n",
       "      <td>This is a very nice piece of work that tackles...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.323757</td>\n",
       "      <td>This is a very nice piece of work that tackles...</td>\n",
       "      <td>34827.0</td>\n",
       "      <td>RA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reject Full Submission</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pos_neg</td>\n",
       "      <td>1.135194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34827</td>\n",
       "      <td>101650.0</td>\n",
       "      <td>The manuscript explores the impact of stochast...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.575787</td>\n",
       "      <td>The manuscript explores the impact of stochast...</td>\n",
       "      <td>34827.0</td>\n",
       "      <td>RA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reject Full Submission</td>\n",
       "      <td>0.0</td>\n",
       "      <td>none</td>\n",
       "      <td>-0.776493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34827</td>\n",
       "      <td>104851.0</td>\n",
       "      <td>Wright and Vetsigian present a work whose cent...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.963397</td>\n",
       "      <td>Wright and Vetsigian present a work whose cent...</td>\n",
       "      <td>34827.0</td>\n",
       "      <td>RA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reject Full Submission</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neg_neg</td>\n",
       "      <td>-1.446239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Reviewer ID  \\\n",
       "Manuscript no.                \n",
       "34827                3163.0   \n",
       "34827              101650.0   \n",
       "34827              104851.0   \n",
       "\n",
       "                                                  CleanedComments    Rec  \\\n",
       "Manuscript no.                                                             \n",
       "34827           This is a very nice piece of work that tackles...  False   \n",
       "34827           The manuscript explores the impact of stochast...  False   \n",
       "34827           Wright and Vetsigian present a work whose cent...  False   \n",
       "\n",
       "                Suitable  ShouldBe  HumanLabel     score  \\\n",
       "Manuscript no.                                             \n",
       "34827              False     False         NaN  3.323757   \n",
       "34827              False     False         NaN  1.575787   \n",
       "34827              False     False         NaN  0.963397   \n",
       "\n",
       "                                                             Text       ms  \\\n",
       "Manuscript no.                                                               \n",
       "34827           This is a very nice piece of work that tackles...  34827.0   \n",
       "34827           The manuscript explores the impact of stochast...  34827.0   \n",
       "34827           Wright and Vetsigian present a work whose cent...  34827.0   \n",
       "\n",
       "               type  ... rev3_decision_dt  rev4_qc_dt rev4_decision  \\\n",
       "Manuscript no.       ...                                              \n",
       "34827            RA  ...              NaN         NaN           NaN   \n",
       "34827            RA  ...              NaN         NaN           NaN   \n",
       "34827            RA  ...              NaN         NaN           NaN   \n",
       "\n",
       "               rev4_decision_dt p.poa_dt  p.vor_dt           FinalDecision  \\\n",
       "Manuscript no.                                                               \n",
       "34827                       NaN      NaN       NaN  Reject Full Submission   \n",
       "34827                       NaN      NaN       NaN  Reject Full Submission   \n",
       "34827                       NaN      NaN       NaN  Reject Full Submission   \n",
       "\n",
       "               outcome review_outcome    zscore  \n",
       "Manuscript no.                                   \n",
       "34827              0.0        pos_neg  1.135194  \n",
       "34827              0.0           none -0.776493  \n",
       "34827              0.0        neg_neg -1.446239  \n",
       "\n",
       "[3 rows x 37 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disagreement_papers.loc[random.choice(disagreement_papers.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 9644: expected 11 fields, saw 13\\nSkipping line 21637: expected 11 fields, saw 12\\nSkipping line 21638: expected 11 fields, saw 12\\nSkipping line 58138: expected 11 fields, saw 12\\nSkipping line 58139: expected 11 fields, saw 12\\nSkipping line 58142: expected 11 fields, saw 12\\nSkipping line 58143: expected 11 fields, saw 12\\n'\n",
      "b'Skipping line 9911: expected 12 fields, saw 14\\nSkipping line 22241: expected 12 fields, saw 13\\nSkipping line 22242: expected 12 fields, saw 13\\nSkipping line 59862: expected 12 fields, saw 13\\nSkipping line 59863: expected 12 fields, saw 13\\nSkipping line 59866: expected 12 fields, saw 13\\nSkipping line 59867: expected 12 fields, saw 13\\n'\n"
     ]
    }
   ],
   "source": [
    "# load initial and reviewer consultations\n",
    "\n",
    "\n",
    "def get_df(path_glob, sep=\"|\"):\n",
    "    out = None\n",
    "    for file in glob.glob(path_glob):\n",
    "        tmp = pd.read_csv(file, error_bad_lines=False, sep=sep) \n",
    "        if out is None:\n",
    "            out = tmp\n",
    "        else:\n",
    "            out = out.append(tmp)\n",
    "    out = out.set_index([\"Manuscript no.\"])\n",
    "    return out\n",
    "\n",
    "initial_consults = get_df(\n",
    "    DATA_ROOT + \"raw/eLife_Initial_Consultation_*_PipeDelimited.txt\")\n",
    "\n",
    "review_consults = get_df(\n",
    "    DATA_ROOT + \"raw/eLife_Reviewer_Consultation_*_PipeDelimited.txt\")\n",
    "\n",
    "reviewers = get_df(DATA_ROOT + \"raw/eLife_Reviewers.csv\", sep=\",\")\n",
    "authors = get_df(DATA_ROOT + \"raw/eLife_Authors.csv\", sep=\",\")\n",
    "authors_orcids = get_df(DATA_ROOT + \"raw/eLife_Authors_ORCIDS.csv\", sep=\",\")\n",
    "gender_reviewers = get_df(DATA_ROOT + \"kyle/gender_reviewers.csv\", sep=\",\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'male'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_reviewers.set_index([\"Reviewer ID\"])\n",
    "gender_reviewers.loc[1141].iloc[0].gender\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get into json with key is paper id and value is\n",
    "# - paper id, outcome, author info\n",
    "# - reviewer info\n",
    "# - official reviews, initial consults, review consults\n",
    "# author info is id, name, gender, institution, city\n",
    "\n",
    "papers_dict = {}\n",
    "for paper_id in set(disagreement_papers.index):\n",
    "    # Skip if only 1 review\n",
    "    if isinstance(disagreement_papers.loc[paper_id], pd.core.series.Series):\n",
    "        continue\n",
    "\n",
    "    papers_dict[paper_id] = {}\n",
    "\n",
    "    def get_reviews():\n",
    "        out = []\n",
    "        \n",
    "        for _, review in disagreement_papers.loc[paper_id].iterrows():\n",
    "            tmp = {}\n",
    "            tmp[\"text\"] = review[\"CleanedComments\"]\n",
    "            tmp[\"score\"] = review[\"score\"]\n",
    "            tmp[\"outcome\"] = review[\"review_outcome\"]\n",
    "            tmp[\"author\"] = str(int(review[\"Reviewer ID\"]))\n",
    "            out.append(tmp)\n",
    "        return out\n",
    "    \n",
    "    def get_consults(df):\n",
    "        out = []\n",
    "\n",
    "        if paper_id not in df.index:\n",
    "            return out\n",
    "\n",
    "        # why is this happening\n",
    "        if isinstance(df.loc[paper_id], pd.core.series.Series):\n",
    "            return \n",
    "\n",
    "        # already sorted by time :)\n",
    "        for _, review in df.loc[paper_id].iterrows():\n",
    "            tmp = {}\n",
    "            tmp[\"text\"] = review[\"Comment text\"]\n",
    "            tmp[\"date\"] = review[\"Comment date\"]\n",
    "            tmp[\"author\"] = str(int(review[\"Commenter ID\"]))\n",
    "            out.append(tmp)\n",
    "        return out\n",
    "\n",
    "    def is_accept():\n",
    "        if isinstance(disagreement_papers.loc[paper_id][\"FinalDecision\"], str):\n",
    "            s = disagreement_papers.loc[paper_id][\"FinalDecision\"]\n",
    "        else:\n",
    "            s = disagreement_papers.loc[paper_id][\"FinalDecision\"].iloc[0]\n",
    "        return 'Accept' in s\n",
    "\n",
    "    def get_reviewers(reviews, target_outcome):\n",
    "        out = []\n",
    "\n",
    "        for review in reviews:\n",
    "            if review[\"outcome\"] == target_outcome:\n",
    "                out.append(review[\"author\"])\n",
    "        return out\n",
    "\n",
    "    papers_dict[paper_id][\"reviews\"] = get_reviews()\n",
    "    papers_dict[paper_id][\"initial_consults\"] = get_consults(initial_consults)\n",
    "    papers_dict[paper_id][\"review_consults\"] = get_consults(review_consults)\n",
    "\n",
    "    papers_dict[paper_id]['is_accept'] = is_accept()\n",
    "    papers_dict[paper_id]['authors'] = [str(int(x)) for x in list(authors.loc[3][\"Author ID\"])]\n",
    "    papers_dict[paper_id]['winning_reviewers'] = \\\n",
    "        get_reviewers(papers_dict[paper_id][\"reviews\"], \"neg_neg\") + \\\n",
    "        get_reviewers(papers_dict[paper_id][\"reviews\"], \"pos_pos\")\n",
    "    papers_dict[paper_id]['losing_reviewers'] = \\\n",
    "        get_reviewers(papers_dict[paper_id][\"reviews\"], \"pos_neg\") + \\\n",
    "        get_reviewers(papers_dict[paper_id][\"reviews\"], \"neg_pos\")\n",
    "    papers_dict[paper_id]['neutral_reviewers'] = get_reviewers(papers_dict[paper_id][\"reviews\"], \"none\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get author metadata together...this takes a few minutes\n",
    "\n",
    "def add_authors(d, df, role):\n",
    "\n",
    "    for pid, row in df.iterrows():\n",
    "        # every csv has person id as 3rd column, and manuscript id is not index\n",
    "        try:\n",
    "            person_id = int(row.iloc[1])\n",
    "        except ValueError:\n",
    "            continue\n",
    "        pid = str(pid)\n",
    "        if \"pids\" not in d[person_id]:\n",
    "            d[person_id][\"pids\"] = [pid]\n",
    "        else:\n",
    "            d[person_id][\"pids\"] += [pid]\n",
    "\n",
    "        if \"roles\" not in d[person_id]:\n",
    "            d[person_id][\"roles\"] = [role]\n",
    "        else:\n",
    "            d[person_id][\"roles\"] += [role]\n",
    "\n",
    "        print()\n",
    "        \n",
    "        # regexes because author/reviewer csvs are different\n",
    "        d[person_id][\"name\"] = row.filter(regex=(\".*name\")).iloc[0]\n",
    "        d[person_id][\"email\"] = row.filter(regex=(\".*email\")).iloc[0]\n",
    "        d[person_id][\"institution\"] = row.filter(regex=(\".*[Ii]nstitution\")).iloc[0]\n",
    "        \n",
    "        city_series = row.filter(regex=(\"[Cc]ity\"))\n",
    "        if not city_series.empty:\n",
    "            d[person_id][\"city\"] = city_series.iloc[0]\n",
    "\n",
    "        country_series = row.filter(regex=(\"[Cc]ity\"))\n",
    "        if not country_series.empty:\n",
    "            d[person_id][\"country\"] = country_series.iloc[0]\n",
    "\n",
    "        \n",
    "people_dict = defaultdict(dict)  \n",
    "add_authors(people_dict, reviewers, \"reviewer\")\n",
    "add_authors(people_dict, authors, \"author\")\n",
    "add_authors(people_dict, authors_orcids, \"author_orchid\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66974\n",
      "2433\n"
     ]
    }
   ],
   "source": [
    "print(len(people_dict))\n",
    "print(len(papers_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/rpryzant/metascience/eLife/data/processed/papers.json', 'w') as fp:\n",
    "    json.dump(papers_dict, fp)\n",
    "\n",
    "with open('/Users/rpryzant/metascience/eLife/data/processed/people.json', 'w') as fp:\n",
    "    json.dump(people_dict, fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
